<!-- Modal post Variational Inference parte 1 -->

{% load staticfiles %}

<div class="portfolio-modal modal fade" id="modal_{{ post.id }}" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="modal-content">
        <a href="" onclick="location.hash='#posts'" class="close-modal" data-dismiss="modal">
            <div class="lr">
                <div class="rl"></div>
            </div>
        </a>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2">
                    <div class="modal-body">
                        <h2>{{ post.name }}</h2>
                        <p class="item-intro text-muted">{{ post.technology }}</p>
                        <img class="img-responsive img-centered" style="width: 600px; height: 275px" src="{{ post.image.url }}" alt="">
                        <div class="row">
                            <p>
                                En los próximos posts os voy a hablar sobre probabilistic machine learning, una rama del machine learning que esta cogiendo
                                bastante importancia en los últimos años. Llevo los últimos meses aprendiendo sobre este campo, concretamente sobre Variational
                                Inference, y creo que puede ser interesante redactar una serie de posts explicando todo lo que he aprendido sobre estos
                                temas gracias a mi sensei <a href="https://twitter.com/CapdevilaPujol" target="_blank">Joan Capdevila</a>.
                            </p>
                            <h3>Probabilistic Machine Learning</h3>
                            <p>
                                En las últimas décadas el estudio del machine learning ha provocado la aparición de una
                                gran variedad de algoritmos para solventar un amplio conjunto de problemas que abarca desde
                                la conducción de vehículos autónomos o la diagnosis médica hasta el reconocimiento del habla
                                o la clasificación de usuarios para campañas de marketing. Estos algoritmos se basan
                                principalmente en la construcción de un modelo que describa lo más fielmente posible los datos.
                            </p>
                            <p>
                                Un modelo es una descripción compacta de unos datos que nos permite hacer predicciones
                                sobre futuras muestras. La principal diferencia entre un modelo de machine learning
                                convencional y un modelo probabilístico es que este último nos permite modelar la incertidumbre, es
                                decir, nos permite saber con qué probabilidad se cumplirá la predicción. Este aspecto puede
                                ser muy valioso en áreas como la medicina o la economía donde el riesgo de tomar una decisión
                                u otra puede ser perjudicial para la salud de un ser humano o suponer una pérdida económica.
                            </p>
                            <p>
                                <figure>
                                    <img class="img-responsive" style="width: 50%; margin-left: 24%"
                                         src="{% static 'img/posts/posts_variational_inference/esquema_situacion.png' %}"
                                         alt="Probabilistic Machine Learning situation">
                                    <figcaption>
                                        <small>Situación del Probabilistic Machine Learning en el área de la inteligencia artifical</small>
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                Este tipo de modelos utiliza la teoría de probabilidad para modelar información a priori, de
                                esta forma el algoritmo no se basa únicamente en los datos de la muestra. También permiten
                                el uso de diferentes datasets de los que aprender, son muy útiles cuando se quieren modelar
                                probabilidades de muchas cosas o se dispone de una cantidad reducida de información y pueden
                                definir modelos complejos con la cantidad de variables aleatorias que se requieran. Estos
                                modelos soportan online learning, es decir, no hace falta reentrenar todo el modelo cada vez que
                                se obtengan nuevos datos sino que simplemente se actualizan las probabilidades. Por otro
                                lado son muy útiles para la toma de decisiones, cuando se requiere una explicación robusta del
                                modelo. En definitiva, se trata de modelos generativos que dan respuesta a múltiples preguntas.
                            </p>
                            <p>
                                A diferencia de los modelos discriminantes que solo modelan la probabilidad de la variable
                                a predecir, un modelo generativo es un modelo probabilístico completo sobre todas las
                                variables (observadas y latentes). Estos modelos pueden utilizarse para simular valores de cualquier
                                variable aleatoria del modelo. Los modelos discriminantes, al no modelar la probabilidad de
                                los datos (la probabilidad de las variables observadas) no pueden modelar relaciones
                                complejas entre las variables observadas y las latentes cosa que los modelos probabilísticos si permiten.
                            </p>
                            <p>
                                La construcción de este tipo de modelos con variables latentes se hace siguiendo la filosofía
                                del Box Loop. El Box Loop es un esquema, creado por el estadístico
                                <a href="https://en.wikipedia.org/wiki/George_E._P._Box" target="_blank">George E. P. Box</a>, sobre el
                                cual se itera repetidas veces durante la construcción de un modelo probabilístico
                            </p>
                            <p>
                                <figure>
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/box_loop.png' %}"
                                         alt="Box loop">
                                    <figcaption>
                                        <small>Esquema gráfico del Box Loop</small>
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                <ol type="1" style="text-align: left">
                                    <li>Primero se construye el modelo probabilístico en base a los conocimientos que se tienen sobre ese entorno.</li>
                                    <li>En segundo lugar se descubren patrones en los datos utilizando el modelo definido previamente y un método de inferencia.</li>
                                    <li>Finalmente se valida el modelo. Si no fuera lo suficientemente bueno se volvería al paso 1 y sino se utilizaría para describir o predecir nuevos datos.</li>
                                </ol>
                            </p>
                            <h3>Bayesian inference</h3>
                            <p>
                                En los métodos tradicionales de machine learning los parámetros del modelo son valores que
                                son determinados por algoritmos de optimización que se encargan de minimizar una función de
                                error. El punto de vista bayesiano es algo diferente, para un bayesiano todos los parámetros
                                desconocidos son descritos mediante distribuciones de probabilidad y la observación de
                                evidencias permite la actualización de estas distribuciones utilizando la regla de Bayes.
                            </p>
                            <h4>Regla de Bayes</h4>
                            <p>
                                Lo primero que hay que tener claro para entender la inferencia bayesiana es la regla de Bayes. La regla de Bayes nos indica como
                                debe actualizarse una probabilidad a priori sobre un suceso después de observar evidencias sobre dicho suceso.
                            </p>
                            <p>
                                <figure style="padding-left: 40%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/bayes_rule.png' %}"
                                         alt="Bayes rule">
                                </figure>
                            </p>
                            <p>
                                A continuación se explica qué son cada uno de los términos de la fórmula siendo x y &theta; los datos y los parámetros del modelo respectivamente:
                                <ul style="text-align: left">
                                    <li><strong>Posterior p(&theta;|x)</strong>: Es la probabilidad de los parámetros dados los datos. En otras palabras, la probabilidad de que el modelo con los
                                        parámetros &theta; haya generado los datos x. El posterior es la incógnita en inferencia bayesiana.</li>
                                    <li><strong>Likelihood p(x|&theta;)</strong>: Es la probabilidad de los datos dados los parámetros.</li>
                                    <li><strong>Prior p(&theta;)</strong>: Es la probabilidad de los parámetros. En este factor de la formula es donde se refleja el conocimiento a priori
                                        que tenemos sobre el modelo (la información que tenemos antes de observar ningún dato).</li>
                                    <li><strong>Evidence p(x)</strong>: Se trata de la evidencia de los datos. Se calcula como &int; p(x,&theta;)d&theta;</li>
                                </ul>
                            </p>
                            <p>
                                El producto p(&theta;|x)p(&theta;) es la probabilidad conjunta: p(&theta;, x).
                            </p>
                            <p>
                                El resumen de esta fórmula sería el siguiente: inicialmente se tiene una creencia (prior) sobre
                                un evento θ (p(θ)), por ejemplo, que la altura de la población de Barcelona sigue una distribución
                                Normal. Después se observa la evidencia (x), una muestra de las alturas de la población de
                                Barcelona. En función de esta evidencia la creencia sobre θ debe cambiar, es decir, la
                                distribución Normal que describía la altura de la población de Barcelona se actualizará.
                                Este cambio lo refleja el posterior (p(θ|x)). Es en este ejemplo donde se puede apreciar
                                claramente el soporte de online learning que permiten este tipo de modelos.
                                Al final se trata de un proceso iterativo de actualización de unas creencias (prior)
                                en base a unas evidencias (x). El posterior de una iteración será el prior de la siguiente.
                            </p>
                            <p>
                                Los algoritmos de inferencia del posterior nos permiten analizar información bajo ciertas suposiciones (priors) infiriendo la estructura
                                oculta que mejor describe nuestros datos. Cuando todas las relaciones entre las variables aleatorias del modelo son
                                <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank">conjugadas</a>
                                el posterior se puede calcular de forma analítica, es el caso de modelos como el Dirichlet-Categorical o Normal Inverse Wishart-Normal.
                                En el caso contrario, el problema de esta fórmula reside en el cálculo de la evidencia. Para muchos modelos de interés (no conjugados)
                                el cálculo del posterior es intratable computacionalmente por culpa de la integral sobre todas las variables latentes de los datos
                                que conlleva el cálculo de la evidencia. Para estos modelos se requiere de otra estrategia para la obtención del posterior por esa razón
                                el cálculo del posterior se convierte en un problema de aproximación.
                            </p>
                            <h4>Aproximación del posterior</h4>
                            <p>
                                El concepto de inferencia bayesiana viene del conjunto de técnicas que se han desarrollado para la aproximación del posterior en modelos
                                complejos o no conjugados. Actualmente existen dos ramas algorítmicas para la aproximación del posterior en inferencia Bayesiana.
                                <ul style="text-align: left">
                                    <li><a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" target="_blank">Markov Chain Monte Carlo (MCMC)</a>:
                                        Sampling approximate inference.</li>
                                    <li><a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods" target="_blank">Variational Inference (VI)</a>:
                                        Structural aproximate inference.</li>
                                </ul>
                            </p>
                            <p>
                                Por un lado, MCMC se basa en la construcción de una cadena de Markov sobre las variables
                                latentes siendo su distribución estacionaria el posterior. Después se ejecuta la cadena hasta que
                                llega al punto de equilibrio. Finalmente el resultado de las muestras de la cadena de Markov
                                en su tramo estacionario, són las muestras del posterior. Los algoritmos más conocidos de esta
                                família son <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" target="_blank">Metropolis–Hastings</a>
                                y <a href="https://en.wikipedia.org/wiki/Gibbs_sampling" target="_blank">Gibbs sampling</a>.
                            </p>
                            <p>
                                Por otro lado, VI aproxima el posterior creando una aproximación analítica, el modelo variacional, el cual va ajustando con
                                el objetivo de reducir la distáncia con el posterior. En esta família de algoritmos el problema deja de ser de aproximación
                                para ser de optimización.
                            </p>
                            <h4>Probabilistic Graphical Models</h4>
                            <p>
                                En el ámbito bayesiano un modelo representa una probabilidad conjunta sobre todas las
                                variables aleatorias del problema.
                                <figure style="padding-left: 38%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/joint_dist.png' %}"
                                         alt="Joint distribution">
                                </figure>
                            </p>
                            <p>
                                Una forma muy práctica de representar estos modelos es mediante los
                                <a href="https://en.wikipedia.org/wiki/Graphical_model" target="_blank">probabilistic graphical
                                models</a>. Un probabilistic graphical model es un grafo dirigido donde los nodos son variables
                                aleatorias y las aristas representan relaciones de dependencia entre dichas variables.
                                Por ejemplo, el probabilistic graphical model de la distribución conjunta:
                                <figure style="padding-left: 36%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/joint_dist2.png' %}"
                                         alt="Joint distribution">
                                </figure>
                                <figure style="padding-left: 34%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/graphical_model.png' %}"
                                         alt="Joint distribution">
                                </figure>
                            </p>
                            <p>
                                En este contexto p(x|y) representa la probabilidad condicional en la cual la distribución de <i>x</i>
                                depende del valor de y. En este tipo de diagramas también existen unos componentes llamados plates.
                            </p>
                            <p>
                                <figure style="padding-left: 44%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/plate.png' %}"
                                         alt="Plate">
                                </figure>
                            </p>
                            <p>
                                Esta notación indica un vector de n variables aleatorias <i>x</i>.
                            </p>
                            <h4>Variables locales y globales</h4>
                            <p>
                                En un modelo probabilístico se pueden distinguir dos tipos de variables aleatorías: globales y
                                locales. Una variable global es aquella que comparten todos los ejemplos del dataset mientras
                                que una variable local es propia de cada ejemplo. Por ejemplo, en el siguiente probabilistic
                                graphical model la variable <i>y</i> es una variable local mientras que la variable <i>z</i> es una variable
                                global. Cuando un nodo aparece oscurecido quiere decir que se trata de un nodo de datos.
                            </p>
                            <p>
                                <figure style="padding-left: 36%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/global_local_variables.png' %}"
                                         alt="Model example">
                                </figure>
                            </p>
                            <h3>Variational inference</h3>
                            <p>
                                En los próximos posts nos centraremos en las diferentes estrategías variacionales para la
                                aproximación del posterior.
                            </p>
                            <h4>Estrategia</h4>
                            <p>
                                Como ya se ha comentado VI consiste en definir una distribución, q(&theta;|&lambda;), cuyos parámetros &lambda; se irán optimizando
                                con el objetivo de reducir sus diferencias con el posterior real p(&theta;|x). Esta nueva distribución es conocida como modelo
                                variacional y el posterior real como modelo probabilístico. En resumen, el objetivo es optimizar los parámetros &lambda; del
                                modelo variacional q(&theta;|&lambda;) de forma que se vaya reduciendo la distancia con el modelo probabilístico p(&theta;|x).
                                A &lambda; también se lo conoce con el nombre de parámetros variacionales.
                            </p>
                            <p>
                                <figure>
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/variational_inference.jpg' %}"
                                         alt="Variational inference">
                                </figure>
                            </p>
                            <h4>Kullback-Leibler divergence</h4>
                            <p>
                                Calcular la distancia Euclidea entre los parámetros de las distribuciones para establecer la similitud entre ambas es una medida
                                demasiado imperfecta puesto que estamos comparando distribuciones y no puntos. <br>
                                Imaginemos una distribución Normal con media 0 y varianza 5, N(0, 5), y otra con media 5 y varianza 5, N(5, 5). Estas dos
                                distribuciones son muy parecidas pero se encuentran a una distancia Euclidea de 5. Si ahora comparamos la primera normal, N(0, 5),
                                con otra normal con media 2 y varianza 7, N(2, 7), parece que son bastante diferentes pero la distancia Euclidea entre ellas es 4.
                                Por esta razón debemos utilizar otra medida de similitud diferente a la Euclidea: la Kullback-Leibler divergence (KL). <br>
                                La KL es una medida de distancia no simétrica (divergencia), es decir, no es lo mismo
                                calcular la KL[p(θ|x)||q(θ|λ)] (forwards KL) que la KL[q(θ|λ)||p(θ|x)] (reverse KL). El hecho de
                                usar una u otra da lugar a algoritmos diferentes:
                                <a href="https://tminka.github.io/papers/ep/minka-ep-uai.pdf" target="_blank">Expectation Propagation</a>
                                usa forwards KL mientras que VI utiliza reverse KL.
                            </p>
                            <p>
                                <figure>
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/kullback-leibler1.png' %}"
                                         alt="Kullback-Leibler visualization">
                                    <figcaption>
                                        <small>
                                            Comparación entre forwards y reverse KL para la aproximación de una distribución
                                            bimodal. La parte azul representa la distribución a aproximar y la roja la aproximación. La
                                            imagen a es una aproximación de forwards KL y las imágenes b y c son aproximaciones de
                                            reverse KL.
                                        </small>
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                <figure>
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/kullback-leibler2.png' %}"
                                         alt="Kullback-Leibler visualization">
                                    <figcaption>
                                        <small>
                                            Comparación entre forwards y reverse KL para la aproximación de una distribución
                                            unimodal. La parte azul representa la distribución a aproximar y la roja la aproximación. La
                                            imagen a es una aproximación de forwards KL y la imagen b es una aproximación de reverse
                                            KL.
                                        </small>
                                    </figcaption>
                                </figure>
                            </p>
                            <p>
                                La definición de esta divergencia es:
                            </p>
                            <p>
                                <figure style="padding-left: 32%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/kl_rule.png' %}"
                                         alt="Kullback-Leibler definition">
                                </figure>
                            </p>
                            <p>
                                Esta divergencia nos permite encontrar la similitud real entre dos distribuciones de probabilidad y es la medida de similitud
                                que el algoritmo de VI minimiza.
                            </p>
                            <h4>Mean-Field assumption</h4>
                            <p>
                                Con el objetivo de definir una distribución tratable sobre todas las variables latentes para aproximar el posterior se simplifica
                                la optimización del modelo variacional suponiendo que se trata de un modelo factorizado. Esto es suponer que q(&theta;|&lambda;)
                                esta compuesta por un conjunto de distribuciones q<sub>i</sub>(&theta;<sub>i</sub>|&lambda;<sub>i</sub>) (de la
                                <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank">Exponential Family</a>).
                                Cada una de estas distribuciones tiene sus parámetros &lambda;<sub>i</sub> los cuales son optimizables individualmente.
                            </p>
                            <p>
                                <figure style="padding-left: 40%">
                                    <img class="img-responsive"
                                         src="{% static 'img/posts/posts_variational_inference/mean_field.png' %}"
                                         alt="Mean-Field assumption">
                                </figure>
                            </p>
                            <br>
                            <div class="well">
                                El objetivo de este post no era otro mas que presentar la idea básica de Variational Inference y a sus principales
                                jugadores. En los próximos posts se entrará en más profundidad en estos algoritmos y se mostrarán las herramientas existentes
                                para la programación de este tipo de modelos. <br>
                            </div>
                            Bienvenidos a Matrix
                            <p>
                            </p>
                            <h5>Referencias</h5>
                            <p>
                                <ul style="text-align: left">
                                    <li>
                                        Journal of the American Statistical AssociationGeorge (E. P. Box)
                                    </li>
                                    <li>
                                        Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models
                                        (David M. Blei)
                                    </li>
                                    <li>
                                        Probabilistic graphical models: principles and techniques
                                        (Koller, Daphne, and Nir Friedman)
                                    </li>
                                    <li>
                                        Model-based Machine Learning
                                        (Christopher M. Bishop)
                                    </li>
                                    <li>
                                        Machine Learning. A probabilistic perspective
                                        (Kevin P. Murphy)
                                    </li>
                                </ul>
                            </p>
                        </div>
                        <ul class="list-inline">
                            <li>Fecha: 09/02/2017</li>
                            <li>Autor: Alberto Pou Quirós</li>
                        </ul>

                        <!-- Comments -->
                        <div class="row">
                            {% include 'blog/partials/comments.html' with post=post %}
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
